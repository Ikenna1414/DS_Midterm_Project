{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/property_listings_flat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"list_price\"])  # drop rows with no price\n",
    "\n",
    "# drop other rows with too many NaNs\n",
    "df = df.dropna(axis=0, thresh=5)  # at least 5 non-NA values to keep row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop text and ID columns that won't help modeling\n",
    "X = df.drop(columns=[\n",
    "    \"list_price\", \n",
    "    \"sold_price\",\n",
    "    \"name\",\n",
    "    \"street_address\",\n",
    "    \"country\",\n",
    "    \"city\",\n",
    "    \"postal_code\",\n",
    "    \"property_id\", \n",
    "    \"listing_id\",\n",
    "    \"property_name\",\n",
    "    \"sold_date\",\n",
    "    \"is_new_listing\",\n",
    "    \"is_new_construction\",\n",
    "    \"county_name\",\n",
    "    \"list_date\",\n",
    "    \"state\"\n",
    "])\n",
    "\n",
    "y = df[\"list_price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df[\"year_built\"] = pd.to_numeric(df[\"year_built\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"year_built\"]).copy()  \n",
    "\n",
    "current_year = datetime.now().year\n",
    "df[\"building_age\"] = current_year - df[\"year_built\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle categorical variables\n",
    "df = df.drop(columns=[\"year_built\"])\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['baths', 'baths_1qtr', 'baths_3qtr', 'baths_full', 'baths_half', 'beds',\n",
      "       'garage', 'lot_sqft', 'sqft', 'stories', 'year_built',\n",
      "       'price_reduced_amount', 'latitude', 'longitude', 'sub_type_townhouse',\n",
      "       'type_condo_townhome_rowhome_coop', 'type_condos',\n",
      "       'type_duplex_triplex', 'type_land', 'type_mobile', 'type_multi_family',\n",
      "       'type_single_family', 'type_townhomes', 'is_price_reduced_True'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN in either X or y\n",
    "# Drop rows with NaN in either X or y\n",
    "X = X.fillna(0)\n",
    "y = y.loc[X.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved and ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "X_train.to_csv(\"../data/processed/X_train.csv\", index=False)\n",
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned data saved and ready for modeling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"R2\": r2_score(y_test, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train: 0\n",
      "NaNs in y_train: 0\n",
      "Infs in X_train: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "print(\"NaNs in X_train:\", X_train.isnull().sum().sum())\n",
    "print(\"NaNs in y_train:\", y_train.isnull().sum())\n",
    "\n",
    "# Check for infinite values\n",
    "import numpy as np\n",
    "print(\"Infs in X_train:\", np.isinf(X_train).sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>36125.617974</td>\n",
       "      <td>10335.831068</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>37547.639983</td>\n",
       "      <td>17763.141721</td>\n",
       "      <td>0.996044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>519710.474811</td>\n",
       "      <td>203639.103992</td>\n",
       "      <td>0.242061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Regressor</th>\n",
       "      <td>606876.769064</td>\n",
       "      <td>242713.010428</td>\n",
       "      <td>-0.033504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   RMSE            MAE        R2\n",
       "Random Forest              36125.617974   10335.831068  0.996338\n",
       "XGBoost                    37547.639983   17763.141721  0.996044\n",
       "Linear Regression         519710.474811  203639.103992  0.242061\n",
       "Support Vector Regressor  606876.769064  242713.010428 -0.033504"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[name] = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
